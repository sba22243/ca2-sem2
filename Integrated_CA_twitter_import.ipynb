{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10effb37-78e4-4382-83fc-6daa1599ba05",
   "metadata": {},
   "source": [
    "# MSc in Data Analytics\n",
    "# Sentiment Analysis\n",
    "\n",
    "Assessment Task\n",
    "Students are advised to review and adhere to the submission requirements documented after the assessment task.  \n",
    "In this continuous assessment, You are required to identify and carry out an analysis of a large dataset gleaned from the twitter API. Instructions for accessing the data can be found here  \n",
    "https://datascienceparichay.com/article/get-data-from-twitter-api-in-python-step-by-step-guide/  \n",
    "https://www.toptal.com/apache/apache-spark-streaming-twitter  \n",
    "OR You may use the data held here:  \n",
    "https://archive.org/details/twitterstream?sort=-publicdate  \n",
    "You must collect at least 1 year's tweets on a topic, this data should be stored as requested below, and you are then required to analyse any change sentiment that occurs over the time period that you have selected.  \n",
    "Following your analysis, you are then required to make a time series forecast of the sentiment at 1 week, 1 month and 3 months going forward. This forecast must be displayed as a dynamic dashboard.   \n",
    "\n",
    "### Assignment\n",
    "Topic: vaccine\n",
    "\n",
    "this notebook will read the dataset containing only the tweeets related to vaccine.  \n",
    "The dataset represent tweets from June 2020 until May 2021\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e37f51d2-b0f8-4081-82bb-f9b941ea2287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "310fe401-7ba7-45ec-90cb-118ed285e3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import col\n",
    "import json, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a166ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43573d91-3b69-492f-b9e8-c2bd2127b8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the directory with the tweets filtered by topic\n",
    "dataset_path = r'/home/hduser/dataset/twitter/topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c32a0dbf-a063-4bb7-89da-05542111bea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Spark Context\n",
    "# fix to manage the error \n",
    "# \"Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"sba22243-step1\") \\\n",
    "    .config(\"spark.sql.debug.maxToStringFields\", 100) \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://127.0.0.1/sba22243.vaccine\") \\\n",
    "    .config(\"spark.mongodb.output.uri\", \"mongodb://127.0.0.1/sba22243.vaccine\") \\\n",
    "    .getOrCreate()\n",
    "sqlContext = spark._wrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c001b02f-4721-4fcf-93de-d8f673542a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataframe = sqlContext.read.json('file://' + dataset_path + '/vaccine-*.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba6d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+-------------+\n",
      "|          created_at|retweeted|                text| timestamp_ms|\n",
      "+--------------------+---------+--------------------+-------------+\n",
      "|Thu Mar 18 16:30:...|    false|WASHINGTON (@AP) ...|1616085014664|\n",
      "|Thu Mar 18 16:30:...|    false|You say this vacc...|1616085017658|\n",
      "|Thu Mar 18 16:30:...|    false|@FauciFan Iâ€™ll ta...|1616085032660|\n",
      "|Thu Mar 18 16:21:...|    false|That EU COVID-19 ...|1616084470665|\n",
      "|Thu Mar 18 16:21:...|    false|@MissCB26 @shungs...|1616084471660|\n",
      "+--------------------+---------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e94a025f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- retweeted: boolean (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- timestamp_ms: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataframe.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79006918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===================================================>  (188 + 3) / 197]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+--------------------+--------------------+\n",
      "|summary|          created_at|                text|        timestamp_ms|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "|  count|              242125|              242125|              242125|\n",
      "|   mean|                null|                null|1.610587907342281...|\n",
      "| stddev|                null|                null|  7.24723910703953E9|\n",
      "|    min|Fri Apr 02 00:02:...|! India starts te...|       1590995006659|\n",
      "|    max|Wed Sep 30 23:59:...|ðŸ©ºðŸ’‰Covid-19: Wil...|       1622527004664|\n",
      "+-------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "dataframe.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b89949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
